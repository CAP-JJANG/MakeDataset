# MakeDataset

### **데이터셋 개요**

음향 신호를 받아 해당 음향 신호가 무슨 알파벳인지 예측하는 모델을 개발하기 위한 데이터셋입니다.

  약 50명의 사람들을 통해 Android 음성녹음 기능으로 테이블 위에서 알파벳 소문자를 썼을 때 생기는 고유한 음향 신호를 녹음하여, 클래스당 약 900개의 음향 데이터를 수집했습니다. 수집한 데이터셋에서 갑자기 폭발적인 신호가 발생하는 Peak 지점을 찾아 Peak 지점부터 음향 파일을 1초를 자르는 함수를 구현했습니다. 1초로 잘린 음향 파일을 wav 파일로 저장하고, 시간-주파수 그래프 형태의 이미지인 스펙트로그램으로 변환했습니다. 

  데이터셋 증강을 위해, wav 파일을 1.25배속과 1.50배속 한 후 스펙트로그램 이미지로 변환하여 원본 데이터의 3배 이미지를 생성했습니다. 뿐만 아니라, 원본 스펙트로그램에서 가로, 세로 한 번씩 랜덤 마스킹을 진행하여 원본 데이터의 3배 이미지를 생성하여 클래스당 약 4500개로 데이터셋을 증강했습니다.


  ### **데이터 처리 순서**

1. toWav.py

   수집한 음향 신호에서 갑자기 폭발적인 신호가 발생하는 peak 지점을 찾아 peak부터 1초를 잘라 wav 파일로 저장합니다.
    
2. toSpeedWav.py

   wav 파일을 1.25배속, 1.50배속합니다.
    
3. WavToSpectrogram.py
   
    1번과 2번에서 얻은 wav 파일을 Librosa 라이브러리를 이용해 스펙트로그램 이미지로 변환합니다.
    
4. resizeImage.py

   이미지 크기를 변환합니다.
    
5. randomMasking.py

   원본 스펙트로그램 이미지에서 가로, 세로 한 번씩 랜덤 마스킹을 진행합니다.

## :raised_hands: ì†Œê°œ
**[ENG]**

This repository contains the process of creating a dataset for learning CSD-Model (a model that receives an acoustic signal and predicts what alphabet the corresponding acoustic signal is).

 About 50 people recorded the unique acoustic signals generated by writing lowercase alphabets on a table with Android voice recording, collecting about 900 acoustic data per class. We implemented a function that cuts the acoustic file by one second from the peak point by finding the peak point where the sudden explosive signal occurs in the collected dataset. A sound file cut to 1 second was saved as a wave file and converted into a spectrogram, an image in the form of a time-frequency graph.

 To augment the dataset, we created a 3-fold image of the original data by converting the wave file to 1.25x and 1.50x and then to a spectrogram image. In addition, random masking was performed once, horizontally and vertically from the original spectrogram to create three times the image of the original data, augmenting the dataset to about 4500 per class.

<br>

**[KOR]**

CSD-Model(ìŒí–¥ ì‹ í˜¸ë¥¼ ë°›ì•„ í•´ë‹¹ ìŒí–¥ ì‹ í˜¸ê°€ ë¬´ìŠ¨ ì•ŒíŒŒë²³ì¸ì§€ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸) í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ì…‹ì„ ë§Œë“œëŠ” ê³¼ì •ì„ ë‹´ì€ ë ˆí¬ì§€í† ë¦¬ì…ë‹ˆë‹¤.

  ì•½ 50ëª…ì˜ ì‚¬ëŒë“¤ì„ í†µí•´ Android ìŒì„±ë…¹ìŒ ê¸°ëŠ¥ìœ¼ë¡œ í…Œì´ë¸” ìœ„ì—ì„œ ì•ŒíŒŒë²³ ì†Œë¬¸ìë¥¼ ì¼ì„ ë•Œ ìƒê¸°ëŠ” ê³ ìœ í•œ ìŒí–¥ ì‹ í˜¸ë¥¼ ë…¹ìŒí•˜ì—¬, í´ë˜ìŠ¤ë‹¹ ì•½ 900ê°œì˜ ìŒí–¥ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤. ìˆ˜ì§‘í•œ ë°ì´í„°ì…‹ì—ì„œ ê°‘ìê¸° í­ë°œì ì¸ ì‹ í˜¸ê°€ ë°œìƒí•˜ëŠ” Peak ì§€ì ì„ ì°¾ì•„ Peak ì§€ì ë¶€í„° ìŒí–¥ íŒŒì¼ì„ 1ì´ˆë¥¼ ìë¥´ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. 1ì´ˆë¡œ ì˜ë¦° ìŒí–¥ íŒŒì¼ì„ wav íŒŒì¼ë¡œ ì €ì¥í•˜ê³ , ì‹œê°„-ì£¼íŒŒìˆ˜ ê·¸ë˜í”„ í˜•íƒœì˜ ì´ë¯¸ì§€ì¸ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ìœ¼ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤. 

  ë°ì´í„°ì…‹ ì¦ê°•ì„ ìœ„í•´, wav íŒŒì¼ì„ 1.25ë°°ì†ê³¼ 1.50ë°°ì† í•œ í›„ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ ì›ë³¸ ë°ì´í„°ì˜ 3ë°° ì´ë¯¸ì§€ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼, ì›ë³¸ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ì—ì„œ ê°€ë¡œ, ì„¸ë¡œ í•œ ë²ˆì”© ëœë¤ ë§ˆìŠ¤í‚¹ì„ ì§„í–‰í•˜ì—¬ ì›ë³¸ ë°ì´í„°ì˜ 3ë°° ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì—¬ í´ë˜ìŠ¤ë‹¹ ì•½ 4500ê°œë¡œ ë°ì´í„°ì…‹ì„ ì¦ê°•í–ˆìŠµë‹ˆë‹¤.


<br><br>
## ğŸ’ª ì£¼ìš” ê¸°ëŠ¥ ë° ìˆœì„œ
**[ENG]**
1. toWav.py
   
   Find the peak point where the sudden explosive signal occurs in the collected acoustic signal and cut 1 second from the peak and save it as a wave file.
2. toSpeedWav.py
   
   1.25x, 1.50x wave files.
3. WavToSpectrogram.py
   
   Use the Librosa library to convert the wave files obtained in #1 and #2 into spectrogram images.
4. resizeImage.py
   
   Convert the image size to 224 X 224.
5. randomMasking.py
    
   Random masking is performed once in a horizontal or vertical manner from the original spectrogram image.

<br>

**[KOR]**
1. toWav.py
   
   ìˆ˜ì§‘í•œ ìŒí–¥ ì‹ í˜¸ì—ì„œ ê°‘ìê¸° í­ë°œì ì¸ ì‹ í˜¸ê°€ ë°œìƒí•˜ëŠ” Peak ì§€ì ì„ ì°¾ì•„ Peakë¶€í„° 1ì´ˆë¥¼ ì˜ë¼ wav íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
2. toSpeedWav.py
   
   wav íŒŒì¼ì„ 1.25ë°°ì†, 1.50ë°°ì†í•©ë‹ˆë‹¤.
3. WavToSpectrogram.py
   
   1ë²ˆê³¼ 2ë²ˆì—ì„œ ì–»ì€ wav íŒŒì¼ì„ Librosa ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
4. resizeImage.py
   
   ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 224 X 224ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
5. randomMasking.py
   
   ì›ë³¸ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì´ë¯¸ì§€ì—ì„œ ê°€ë¡œ, ì„¸ë¡œ í•œ ë²ˆì”© ëœë¤ ë§ˆìŠ¤í‚¹ì„ ì§„í–‰í•©ë‹ˆë‹¤.
   
   

<br><br>
## ğŸ¦¾Â ì£¼ìš” ê¸°ìˆ 

* PyCharm IDE
* Python: 3.9.13
* Ipython: 8.15.0
* Librosa: 0.10.1
* Matplotlib: 3.7.2
* Numpy: 1.25.2
* Pandas: 2.1.1
* Pillow: 10.0.1
* Pydub: 0.25.1


<br><br>
## â­ï¸ ì„¤ì¹˜ ë°©ë²•
1. clone [github ë¦¬í¬ì§€í† ë¦¬ ì£¼ì†Œ]
2. ê°€ìƒí™˜ê²½ ìƒì„±
   ```
   python -m venv venv
   ```
   ë˜ëŠ”
   
   ```
   python3 -m venv venv
   ```
3. ê°€ìƒí™˜ê²½ ì‹¤í–‰
    - Windows
       ```
       venv\Scripts\activate
       ```
    - macOS ë° Linux
       ```
       source venv/bin/activate
       ```
4. pip ìµœì‹ ë²„ì „ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ
   ```
   python -m pip install â€”upgrade pip
   ```
    ë˜ëŠ”
    
   ```
   python3 -m pip install â€”upgrade pip
   ```
5. íŒ¨í‚¤ì§€ ì„¤ì¹˜
   ```
   pip install -r requirements.txt
   ```
   ë˜ëŠ”
   
   ```
   pip3 install -r requirements.txt
   ```
6. ìˆœì„œëŒ€ë¡œ í”„ë¡œì íŠ¸ Run

<br><br>
## ğŸ¤– ë¼ì´ì„¼ìŠ¤
This project is licensed under the Apache License 2.0 - see the [LICENSE](https://github.com/CAP-JJANG/MakeDataset/blob/main/LICENSE) file for details.  
[OSS Notice](https://github.com/CAP-JJANG/MakeDataset/blob/main/OSS-Notice.md) sets forth attribution notices for third party software that may be contained in this application.

